# .env.example
# Copia este archivo a `.env.local` (o pon las mismas variables en tu entorno) y NO lo subas al repositorio.
# Variables de entorno usadas por `api/hf-proxy.js` (servidor):

# Token secreto de Hugging Face (no lo expongas al cliente)
HF_TOKEN=tu_huggingface_token_aqui

# Modelo por defecto a usar en el proxy. Ejemplos:
# - google/flan-t5-small
# - gpt2
# - nombre_de_usuario/nombre_del_modelo_en_hf
HF_MODEL=google/flan-t5-small

# --- Notas ---
# 1) Para desarrollo local con Vite: crea un archivo `.env.local` en la raíz con las mismas variables
#    y reinicia el servidor de desarrollo para que `process.env.HF_TOKEN` esté disponible en Node.
#    Ejemplo (no incluyas esto en git):
#      HF_TOKEN=abcd1234
#      HF_MODEL=google/flan-t5-small

# 2) En Vercel (producción / preview): añade estas variables en el Dashboard del proyecto
#    Project -> Settings -> Environment Variables. Usa los mismos nombres (HF_TOKEN, HF_MODEL).

# 3) ¿Dónde consigo HF_TOKEN?
#    - Ve a https://huggingface.co/
#    - Inicia sesión (o crea una cuenta)
#    - Ve a https://huggingface.co/settings/tokens
#    - Crea un token nuevo (tipo "Read" o "Inference") y pégalo en `HF_TOKEN`.

# 4) Seguridad:
#    - NUNCA pongas HF_TOKEN en archivos que terminen subidos al cliente (por ejemplo, variables que comiencen con VITE_)
#    - Para producción, configura las variables en el panel de Vercel y no en el repositorio.

# 5) Si usas otro proveedor (p.ej. OpenAI), crea variables similares (p.ej., OPENAI_API_KEY) y modifica `api/hf-proxy.js`
#    o crea un nuevo proxy para ese proveedor.
